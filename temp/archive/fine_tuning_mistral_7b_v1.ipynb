{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -q -U transformers\n",
    "# %pip install -q -U accelerate\n",
    "# %pip install -q -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing, quantizing, fine-tuning, merging, and saving mistral-7b."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mistral 7B Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a 4-bit quantization with NF4-type configuration using BitsAndBytes to load the model in 4-bit precision. It will help load the model faster and reduce the memory footprint so that it can be run on Google Colab Kaggle Notebook, or consumer GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline\n",
    "import torch\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the model and tokenizer using the transformer library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62e28cec03d441809bb7654c6357956d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"mistralai/Mistral-7B-v0.1\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        # load_in_4bit=True,\n",
    "        quantization_config=bnb_config,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the pipeline (to generate a response based on the prompt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\n",
    "    \"text-generation\", \n",
    "    model=model, \n",
    "    tokenizer = tokenizer, \n",
    "    torch_dtype=torch.bfloat16, \n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As a data scientist, can you explain the concept of regularization in machine learning?\n",
      "\n",
      "Answer: In machine learning, regularization is a technique used to prevent overfitting in the model and improve generalization. Overfitting occurs when a model fits too closely to the training data, resulting in poor performance on new, unseen data. Regularization adds a penalty term to the loss function, which encourages simpler models that generalize better. This can be achieved through various techniques such as L1/L2 regularization, dropout, and early stopping.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"As a data scientist, can you explain the concept of regularization in machine learning?\"\n",
    "\n",
    "sequences = pipe(\n",
    "    prompt,\n",
    "    do_sample=True,\n",
    "    max_new_tokens=100, \n",
    "    temperature=0.7, \n",
    "    top_k=50, \n",
    "    top_p=0.95,\n",
    "    num_return_sequences=1,\n",
    ")\n",
    "print(sequences[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mistral 7B Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# %pip install -U bitsandbytes\n",
    "# %pip install -U transformers\n",
    "# %pip install -U peft\n",
    "# %pip install -U accelerate\n",
    "# %pip install -U trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig,HfArgumentParser,TrainingArguments,pipeline, logging\n",
    "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\n",
    "import os,torch, wandb\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "HUGGING_FACE_FINE_TUNING_WRITE_ACCESS_TOKEN = os.getenv(\"HUGGING_FACE_FINE_TUNING_WRITE_ACCESS_TOKEN\")\n",
    "WANDB_API_KEY = os.getenv(\"WANDB_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/marx/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login --token $HUGGING_FACE_FINE_TUNING_WRITE_ACCESS_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmajestic-shawarma\u001b[0m (\u001b[33mnesvier\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/marx/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/opt/finetune_forge/temp/wandb/run-20240418_142847-1u4jgq4x</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nesvier/Fine-tuning%20Mistral-7B-Chapterizaton/runs/1u4jgq4x' target=\"_blank\">worthy-frost-1</a></strong> to <a href='https://wandb.ai/nesvier/Fine-tuning%20Mistral-7B-Chapterizaton' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nesvier/Fine-tuning%20Mistral-7B-Chapterizaton' target=\"_blank\">https://wandb.ai/nesvier/Fine-tuning%20Mistral-7B-Chapterizaton</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nesvier/Fine-tuning%20Mistral-7B-Chapterizaton/runs/1u4jgq4x' target=\"_blank\">https://wandb.ai/nesvier/Fine-tuning%20Mistral-7B-Chapterizaton/runs/1u4jgq4x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.login(key = WANDB_API_KEY)\n",
    "run = wandb.init(\n",
    "    project='Fine-tuning Mistral-7B-Chapterizaton', \n",
    "    job_type=\"training\", \n",
    "    anonymous=\"allow\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = \"mistralai/Mistral-7B-v0.1\"\n",
    "dataset_name = \"MajesticShawarma/chapterization-v0.1\"\n",
    "new_model = \"mistral_7b_chapterizaton_4bit_v0.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cacheHit': False,\n",
       " 'durationMs': 13242,\n",
       " 'input': {'max_tokens': 4096,\n",
       "  'messages': [{'content': 'You are tasked with extracting relevant information or identification from the following key-value pairs. Given a piece of text, chapterize and generate a JSON format as output. Follow the instructions below to help you in generating the output:\\n\\n1. **Understand the Key-Value Structure:**\\n   - A key-value pair consists of:\\n      - `\\'summary\\'`: A top-level overview or description of the chunk. Must not be empty (i.e., required).\\n      - `\\'headers\\'`: A list of headers where a header is a line of text that introduces a new section or chapter in a document. It is typically formatted distinctly from the main body text to stand out, often being bolder, in a larger font, or differently styled. Headers are concise, summarizing the content that follows, and they guide the reader through the document\\'s structure. Strictly, this is a list of strings. Must not be empty (i.e., required).\\n      - `\\'subheaders\\'`: A list of subheaders where subheaders are similar to headers but usually introduce subsections within a larger section. They are often formatted to be slightly less prominent than main headers, but still distinct from the body text. Strictly, this is a list of strings. Must not be empty (i.e., required).\\n      - `\\'named_entities\\'`: A list of dictionary of named entities identified in the text. Must not be empty (i.e., required).\\n      - `\\'keypoints\\'`: A list of the most important elements or essential information conveyed in the given text chunk. Must not be empty (i.e., required).\\n      - `\\'tonality\\'`: The overall tone or sentiment of the text chunk, such as positive, negative, neutral, or mixed. Must not be empty (i.e., required).\\n\\n2. **Extract Relevant Information:**\\n   - Focus on extracting the most relevant information or identification from each chunk. This could include key themes, essential concepts, or significant details.\\n\\n3. **Perform Named Entity Recognition:**\\n   - Extract named entities from a given text and organize the results, providing the option for individual descriptions for each entity. \\n   - As part of the information extraction, identify and categorize any named entities, including but not limited to PERSON, ORGANIZATION, LOCATION, etc., within the text.\\n   - The system should present the extracted entities in a structured format, allowing for detailed descriptions or additional information for each identified entity.  \\n   - Follow exactly the example below for the named entities:\\n\\n      named_entities = [\\n         {\\n            \"<Tag_1>\": [\\n                  {\"entity\": \"<Entity_1>\", \"description\": \"<Description_1a>\"},\\n                  {\"entity\": \"<Entity_2>\", \"description\": \"<Description_1b>\"},\\n                  # Add more entities with individual descriptions as needed\\n            ]\\n         },\\n         {\\n            \"<Tag_2>\": [\\n                  {\"entity\": \"<Entity_3>\", \"description\": \"<Description_2>\"},\\n                  {\"entity\": \"<Entity_4>\", \"description\": \"<Description_2>\"},\\n                  # Add more entities with a common description as needed\\n            ]\\n         },\\n         # Add more entries as needed\\n      ]\\n   \\n   <Tag_1> and <Tag_2> represent different types of named entities.\\n   Each tag contains a list of dictionaries, where each dictionary represents an entity and its associated description.\\n   Each entity can have an individual description.\\n\\n\\n4. **Determine the Tonality:**\\n   - Assess the overall tone or sentiment of the text chunk, such as positive, negative, neutral, or mixed. Include this assessment under the key `\\'tonality\\'`.\\n\\n5. **Highlight the Keypoints:**\\n   - Identify and list the most important elements or essential information conveyed in the given chunk under the key `\\'keypoints\\'`.\\n\\n6. **Header Detection:**\\n   - Analyze the text for characteristics typical to headers of a document:\\n      - Capitalization: Look for any title case or all uppercase.\\n      - Position: Consider if any text is at the beginning of a section or stands alone.\\n      - Content: Assess if the text is concise and focused.\\n      - Numbering/Symbols: Note any numbering or special symbols.\\n      - Contextual Relevance: Evaluate if any text introduces a new topic or section.\\n\\n7. **Subheader Detection:**\\n   - Analyze the text for characteristics typical of subheaders of a document:\\n      - Capitalization: Subheaders often follow title case, but they might not always be in all uppercase, unlike some main headers.\\n      - Position: Check if the text appears within a section, usually following a main header. Subheaders are often used to introduce subtopics within a larger section.\\n      - Content: Determine if the text is more specific than a main header but still concise. It should elaborate on the content introduced by the main header.\\n      - Numbering/Symbols: Look for secondary or nested numbering or bullet points (e.g., \"1.1 Subsection\", \"• Subpoint\").\\n      - Contextual Relevance: Evaluate if the text refines or narrows down the topic introduced by the main header, rather than introducing a completely new topic.\\n\\n8. **Generate Tags**\\n   - Please generate tags based on the given relevant information and strictly refrain from generating empty tags or empty array.\\n\\n9. **Provide Clear Details:**\\n   - Clearly present the information extracted from the piece of text. Ensure that the details are concise and informative.\\n\\n10. **Strict JSON Response:**\\n   - Strictly format your response as a JSON object. Each key-value pair should adhere to the specified structure.\\n\\n         Example Key-Value Pair:\\n            {\\n               \"summary\": \"It explores potential applications and future directions of research, including constructing dynamic knowledge graphs for specialized verticals, enhancing KGTransformer capabilities using self-supervised learning, combining language models with knowledge graphs, comparing graph learning techniques with traditional time-series models, and architectural improvements to KGTransformer.\",\\n               \"headers\": [\"Introduction\", \"Methodology\", \"Discussion\"],\\n               \"subheaders\": [\"Introduction to the Study\", \"Background and Context\", \"Research Methodology\", \"Implications of Results\", \"Future Research Directions\"],\\n               \"named_entities\": \\n                  [\\n                     {\\n                        \"Persons\": [\\n                              {\"entity\": \"John Doe\", \"description\": \"Lead author of the study\"},\\n                              {\"entity\": \"Jane Smith\", \"description\": \"Co-author and contributor\"}\\n                        ]\\n                     },\\n                     {\\n                        \"Organization\": [\\n                              {\"entity\": \"7Gen\", \"description\": \"Primary research organization\"},\\n                              {\"entity\": \"XYZ Foundation\", \"description\": \"Supporting foundation\"}\\n                        ]\\n                     },\\n                     {\\n                        \"Location\": [\\n                              {\"entity\": \"New York\", \"description\": \"Study conducted in New York\"},\\n                              {\"entity\": \"London\", \"description\": \"Collaboration with researchers in London\"}\\n                        ]\\n                     }\\n                  ],\\n               \"keypoints\": [\"Recent breakthroughs in machine learning\", \"Advancements in neural network technologies\", \"Ethical considerations in AI development\"],\\n               \"tonality\": \"Mixed\",\\n               \"tags\": [\"AI\", \"machine learning\", \"neural network\", \"graph\", \"research\"]\\n            }\\n\\nYour task is to strictly generate a JSON response that extracts and presents relevant information or identification for each key-value pair. I want your response to be in valid JSON format only and nothing else.\\n',\n",
       "    'role': 'system'},\n",
       "   {'content': 'Here is the text passage: ” Then she \\nlooked confused and said, “Is that too much to ask? I really don’t \\nknow. ” Since childhood, Meaghan had been trained to think that \\nher natural desire to feel special and loved was selfish. Throughout her marriage, her husband reinforced this by telling \\nher that she wanted too much and her expectations were too \\nhigh— until she stopped believing that he knew more about her \\nthan she did. Lacking Self- Confidence Due to \\nParental Rejection\\nWhen parents reject or emotionally neglect their children, these children \\noften grow up to expect the same from other people. They lack confidence \\nthat others could be interested in them. Instead of asking for what they \\n\\n\\n\\nAdult Children of Emotionally Immature Parents\\n\\n20\\n\\nwant, their low self- confidence makes them shy and conflicted about \\nseeking attention. They’re convinced they would be bothering others if \\nthey tried to make their needs known. Unfortunately, by expecting past \\nrejection to repeat itself, these children end up stifling themselves and \\npromoting more emotional loneliness. In this situation, people create their own emotional loneliness by \\nhanging back instead of interacting. As a therapist, my job is to help them \\nrealize how their parents have damaged their self- confidence while also \\nencouraging them to tolerate the anxiety of trying something new in order \\nto connect more with others. As the next two stories show, people are \\ncapable of doing this; it just may not occur to them to reach out because \\nthey simply don’t have much experience with other people helping them \\nfeel better. Ben’s Story\\nBen had suffered from anxiety and depression for much of his life. He characterized his mother as a rejecting woman who kept him at \\narm’s length. She was imperious and had made it clear that he held \\na low place in the family pecking order. As a child, Ben’s needs and \\nfeelings simply weren’t a primary concern, and he was expected to \\nwait until the adults were ready to pay attention to him. Fortunately, Ben married a kind and affectionate woman, \\nAlexa. But he was baffled as to why she had chosen him. As he \\nput it, “I’m not a very interesting person. I don’t know why Alexa \\nlikes me. I’m not exactly a nobody, but…” The way Ben’s voice \\ntrailed off indicated that he saw himself as someone who could \\neasily be overlooked and taken for granted. Ben’s childhood \\nexperience of his mother’s rejection had clearly deflated his \\nself- confidence. Further, it had convinced him that others would \\nfind his emotional needs as repugnant as his mother had. One day in session, Ben talked about how unhappy and \\noverwhelmed he was feeling. When I asked if he’d confided in \\nAlexa about how he was feeling, he said, “No, I can’t. She’s got \\nher own stuff to deal with. I don’t want her to see me as this wuss \\n\\n\\n\\nHow EI Parents Affect Their Adult Children’s Lives \\n\\n21\\n\\nwho can’t deal with his own issues. ” When I said it seemed \\nunlikely Alexa would do that, he agreed: “I know she loves me for \\njust being myself. But I don’t feel that way about myself. ”\\n\\nWhen I suggested to Ben that he could try opening up to \\nAlexa, given how supportive she was, he told me he thought he \\nshould be more self- reliant, saying, “I should be able to weather this \\non my own. Isn’t it up to me to meet my own emotional needs?”\\n\\nWhat a lonely thought. I told Ben that we all need other \\npeople to meet our emotional needs for comfort and closeness. That’s what relationships are all about. Charlotte’s Story\\nCharlotte provides another example of this tendency to see \\ncurrent situations through the lens of past parental rejection. She \\nhad finally accepted a friend’s repeated invitations to enter a short \\nstory in a writing contest. She was sure the judges would reject her \\nwork, even though she was a successful newspaper journalist. To \\nher astonishment, she won. For Charlotte, this stirred up painful memories of all the \\ntimes in childhood when she was criticized and shamed by her \\nparents for trying to stand out. Her parents weren’t capable of \\nemotional support and instead found reasons to disparage her \\naccomplishments. Now, even as she was thrilled about her award, \\nshe simultaneously felt terrified that someone would step forward \\nto mock her or expose her as undeserving. Instead of sharing her \\nhappiness with everyone, she kept it to herself, telling herself no \\none was interested. Childhood Loneliness Beneath \\nAdult Success\\nParental rejection doesn’t always result in low self- confidence. Some intel-\\nligent, resilient people somehow manifest the confidence to pursue good \\n\\n\\n\\nAdult Children of Emotionally Immature Parents\\n\\n22\\n\\ncareers and reach high levels of achievement. Many find emotionally \\nmature partners, enjoy satisfying long- term relationships, and create close \\nfamilies of their own. But despite their emotional needs being met in \\ncurrent relationships, the lingering trauma of childhood loneliness may \\nhaunt them in other ways, through anxiety, depression, or bad dreams. Natalie’s Story\\nNatalie, fifty, an award- winning business consultant, was an \\nemotionally neglected child who nevertheless created a rewarding \\nadult life for herself both personally and professionally. Unfortunately, the emotional neglect she experienced as a child \\nstill haunts her in the form of dreams, which she described like \\nthis: “I have recurring nightmares with the same theme. I’m in a \\ndesperate situation that I can’t get out of. I’m trying frantically to \\nfind a solution, a way out. Different roads, different keys, different \\ndoors— none of them are a solution. I’m all alone, and there’s only \\nme trying to solve the problem; there’s no one else. Lots of times \\nI’m responsible for other people who are watching and waiting for \\nme to fix everything, but here they give me no help. There is no \\ncomfort to be found. I have no protection and I’m not safe. Then I \\nwake up and my heart is racing. ”\\n\\nNatalie’s dream captures what it feels like to be emotionally \\nalone. She has to deal with everything by herself and doesn’t \\nconsider asking anyone for help. This is how children of \\nemotionally immature parents feel. Their parents may technically \\nbe present, but they offer little help, protection, or comfort. In her family life, Natalie still takes care of her elderly mother, \\nwho lives with Natalie and her husband and kids. But no matter \\nhow much Natalie does, her mother still complains that Natalie \\nhas never loved her or helped her enough. Since childhood, \\nNatalie has felt the responsibility for her mother’s emotional state. Meanwhile, Natalie was on her own because her mother wasn’t a \\nperson she could turn to. Children like Natalie often grow up as \\nlittle adults, helping their parents, giving them no trouble, and \\n\\n\\n\\nHow EI Parents Affect Their Adult Children’s Lives \\n\\n23\\n\\nappearing to need practically nothing. These capable kids may \\nseem like they can parent themselves, but they can’t. No child \\ncan. They just learn to cling to whatever emotional scraps they get \\nbecause any connection is better than none at all. Yet who would guess Natalie’s early insecurities as she strides \\ninto meetings, all business in her impeccable suits? She has a good \\nmarriage, successful children, and close friendships. She knows \\nhow to relate to people from all walks of life, and her emotional \\nintelligence is off the charts. Natalie’s dreams pull back the \\ncurtain to reveal the emotional loneliness that remains within her. Despite creating a fulfilling adult life, inside she remains \\nvulnerable to anxieties about being alone and unsupported. Not \\nuntil she was nearly fifty did she begin to understand how her \\nrelationship with her mother fueled her underlying feelings of \\nanxiety. That was one of the most meaningful discoveries of her \\nlife. Finally, she saw the reason for those nightmares. Why It Feels So Bad to Live Without \\nEmotional Connection\\nThere’s a reason why people have such a strong need for emotional con-\\nnection with others. Throughout human evolution, being part of a group \\nhas always meant more safety and less stress. Our ancestors who most \\ndisliked separation were more likely to survive because they enjoyed the \\nsafe feeling of being close to others. Early humans who didn’t mind isola-\\ntion, on the other hand, may have been comfortable with more distance \\nthan was good for their survival. So when you’re longing for a deep emotional connection, remind \\nyourself that your painful feeling of aloneness is coming not just from your \\nindividual history, but also from human genetic memory. Just like you, our \\ndistant ancestors had a strong need for emotional closeness. Your need for \\nattention and connection is as old as the human race. You have prehistoric \\nreasons for not liking to be lonely. Adult Children of Emotionally Immature Parents\\n\\n24\\n\\nSummary\\nA lack of emotional intimacy creates emotional loneliness in both chil-\\ndren and adults. Attentive and reliable emotional relationships are the \\nbasis of a child’s sense of security. Unfortunately, emotionally immature \\nparents are usually too uncomfortable with closeness to give their children \\nthe deep emotional connection they need. Parental neglect and rejection \\nin childhood can adversely affect self- confidence and relationships in \\nadulthood, as people repeat old, frustrating patterns and then blame \\nthemselves for not being happy. Even adult success doesn’t completely \\nerase the effects of parental disconnection earlier in life.',\n",
       "    'role': 'user'}],\n",
       "  'model': 'gpt-4-0125-preview',\n",
       "  'response_format': {'type': 'json_object'},\n",
       "  'temperature': 0,\n",
       "  'timeout': 120},\n",
       " 'output': {'choices': [{'finish_reason': 'stop',\n",
       "    'index': 0,\n",
       "    'message': {'content': '{\\n  \"summary\": \"The passage discusses the impact of emotionally immature parents on their children\\'s adult lives, highlighting issues like low self-confidence, emotional loneliness, and the struggle for emotional intimacy. It emphasizes the importance of emotional connections and how the lack of such connections in childhood due to parental neglect or rejection can lead to difficulties in forming healthy relationships in adulthood. The text also explores the stories of individuals who, despite achieving success, continue to grapple with the emotional scars left by their upbringing.\",\\n  \"headers\": [\"Lacking Self-Confidence Due to Parental Rejection\", \"How EI Parents Affect Their Adult Children’s Lives\", \"Childhood Loneliness Beneath Adult Success\", \"Why It Feels So Bad to Live Without Emotional Connection\", \"Summary\"],\\n  \"subheaders\": [\"Ben’s Story\", \"Charlotte’s Story\", \"Natalie’s Story\"],\\n  \"named_entities\": [\\n    {\\n      \"Persons\": [\\n        {\"entity\": \"Meaghan\", \"description\": \"A character reflecting on her upbringing and marriage.\"},\\n        {\"entity\": \"Ben\", \"description\": \"A man who suffers from anxiety and depression, reflecting on his mother\\'s rejection.\"},\\n        {\"entity\": \"Alexa\", \"description\": \"Ben\\'s kind and affectionate wife.\"},\\n        {\"entity\": \"Charlotte\", \"description\": \"A successful journalist who doubts her worth due to childhood criticism.\"},\\n        {\"entity\": \"Natalie\", \"description\": \"An award-winning business consultant dealing with the emotional neglect of her childhood.\"}\\n      ]\\n    },\\n    {\\n      \"Professions\": [\\n        {\"entity\": \"Therapist\", \"description\": \"The narrator providing insights and helping individuals.\"},\\n        {\"entity\": \"Newspaper Journalist\", \"description\": \"Charlotte\\'s profession.\"},\\n        {\"entity\": \"Business Consultant\", \"description\": \"Natalie\\'s profession.\"}\\n      ]\\n    }\\n  ],\\n  \"keypoints\": [\\n    \"Emotionally immature parents can cause their children to suffer from low self-confidence and emotional loneliness.\",\\n    \"Adults with such upbringing struggle to form healthy emotional connections.\",\\n    \"Success in adulthood does not erase the emotional scars of parental neglect.\",\\n    \"The stories of Ben, Charlotte, and Natalie illustrate the varied impacts of emotional immaturity in parents.\",\\n    \"Emotional connection is crucial for human survival and well-being.\"\\n  ],\\n  \"tonality\": \"Mixed\",\\n  \"tags\": [\"Emotional Immaturity\", \"Parental Neglect\", \"Self-Confidence\", \"Emotional Loneliness\", \"Adult Relationships\", \"Therapy Insights\"]\\n}',\n",
       "     'role': 'assistant'}}],\n",
       "  'created': 1711776037,\n",
       "  'id': 'chatcmpl-98LQrlgnFeHgUhWQnIe0IDiOa6UTX',\n",
       "  'model': 'gpt-4-0125-preview',\n",
       "  'object': 'chat.completion',\n",
       "  'system_fingerprint': 'fp_a7daf7c51e',\n",
       "  'usage': {'completion_tokens': 527,\n",
       "   'prompt_tokens': 3546,\n",
       "   'total_tokens': 4073}},\n",
       " 'tags': {'$sdk': 'python',\n",
       "  '$sdk.version': '4.4.2',\n",
       "  'chapterization_algo_version': '0.0.1-Marx',\n",
       "  'chunk_number': '6',\n",
       "  'file_extraction_algo_version': '0.0.1-Marx',\n",
       "  'file_name': 'Adult Children of Emotionally Immature Parents How to Heal from Distant, Rejecting, or Self-Involved Parents - Lindsay C. Gibson.pdf',\n",
       "  'is_pruning_enabled': 'false',\n",
       "  'max_tokens': '4096',\n",
       "  'prompt_id': '2b0e94f029c18c2f64f35dbd3e6c62ed1e193bedf9d014401474a0cc1b53b106',\n",
       "  'response_format_type': 'json_object',\n",
       "  'source_data_version': '0.0.1-Marx',\n",
       "  'temperature': '0',\n",
       "  'timeout': '120',\n",
       "  'type': 'chapterization'}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing the dataset\n",
    "dataset = load_dataset(dataset_name, split=\"train\")\n",
    "dataset[\"items\"][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11aaba5be5724958acccecaa1e2c7315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bnb_config = BitsAndBytesConfig(  \n",
    "    load_in_4bit= True,\n",
    "    bnb_4bit_quant_type= \"nf4\",\n",
    "    bnb_4bit_compute_dtype= torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant= False,\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "        base_model,\n",
    "        # load_in_4bit=True,\n",
    "        quantization_config=bnb_config,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True,\n",
    ")\n",
    "model.config.use_cache = False # silence the warnings\n",
    "model.config.pretraining_tp = 1\n",
    "model.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\n",
    "tokenizer.padding_side = 'right'\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.add_eos_token = True\n",
    "tokenizer.add_bos_token, tokenizer.add_eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = prepare_model_for_kbit_training(model)\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\"gate_proj\"]\n",
    ")\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
